"""
RAGç³»ç»Ÿ Day 4-5 æµ‹è¯•å¥—ä»¶
æµ‹è¯•æ£€ç´¢æœåŠ¡ï¼šè¯­ä¹‰æœç´¢ã€å…³é”®è¯æœç´¢ã€æ··åˆæ£€ç´¢ã€é‡æ’åº
"""
import asyncio
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

from app.rag.retrieval_service import (
    RetrievalService, get_retrieval_service,
    RetrievalMode, RetrievalResult
)
from app.rag.embedding_service import get_embedding_service, EmbeddingProvider
from app.rag.vector_store import get_vector_store, Document
from app.rag.document_processor import get_document_processor


async def test_setup():
    """è®¾ç½®æµ‹è¯•ç¯å¢ƒï¼šåˆ›å»ºæµ‹è¯•æ–‡æ¡£å¹¶å­˜å…¥å‘é‡æ•°æ®åº“"""
    print("\n" + "="*60)
    print("æµ‹è¯•å‡†å¤‡: åˆ›å»ºæµ‹è¯•æ–‡æ¡£åº“")
    print("="*60)
    
    # åˆ›å»ºæµ‹è¯•æ–‡æ¡£
    test_docs = [
        {
            "content": """Pythonæ˜¯ä¸€ç§é«˜çº§ç¼–ç¨‹è¯­è¨€ï¼Œç”±Guido van Rossumåˆ›å»ºã€‚
Pythonå…·æœ‰ç®€æ´æ¸…æ™°çš„è¯­æ³•ï¼Œå¼ºå¤§çš„æ ‡å‡†åº“ï¼Œå¹¿æ³›åº”ç”¨äºWebå¼€å‘ã€æ•°æ®åˆ†æã€äººå·¥æ™ºèƒ½ç­‰é¢†åŸŸã€‚
Pythonçš„è®¾è®¡å“²å­¦å¼ºè°ƒä»£ç çš„å¯è¯»æ€§å’Œç®€æ´çš„è¯­æ³•ã€‚""",
            "metadata": {"title": "Pythonç®€ä»‹", "category": "programming", "language": "python"}
        },
        {
            "content": """æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œé€šè¿‡ç®—æ³•è®©è®¡ç®—æœºä»æ•°æ®ä¸­å­¦ä¹ ã€‚
å¸¸è§çš„æœºå™¨å­¦ä¹ ç®—æ³•åŒ…æ‹¬çº¿æ€§å›å½’ã€å†³ç­–æ ‘ã€ç¥ç»ç½‘ç»œç­‰ã€‚
Pythonæ˜¯æœºå™¨å­¦ä¹ é¢†åŸŸæœ€æµè¡Œçš„ç¼–ç¨‹è¯­è¨€ï¼ŒTensorFlowå’ŒPyTorchæ˜¯ä¸»æµæ¡†æ¶ã€‚""",
            "metadata": {"title": "æœºå™¨å­¦ä¹ åŸºç¡€", "category": "ai", "language": "python"}
        },
        {
            "content": """æ•°æ®åº“æ˜¯å­˜å‚¨å’Œç®¡ç†æ•°æ®çš„ç³»ç»Ÿã€‚SQLæ•°æ®åº“ä½¿ç”¨ç»“æ„åŒ–æŸ¥è¯¢è¯­è¨€ã€‚
NoSQLæ•°æ®åº“åŒ…æ‹¬MongoDBã€Redisç­‰ï¼Œé€‚åˆå¤„ç†éç»“æ„åŒ–æ•°æ®ã€‚
å‘é‡æ•°æ®åº“å¦‚ChromaDBä¸“é—¨ç”¨äºå­˜å‚¨å’Œæ£€ç´¢å‘é‡æ•°æ®ã€‚""",
            "metadata": {"title": "æ•°æ®åº“æ¦‚è¿°", "category": "database", "language": "general"}
        },
        {
            "content": """Webå¼€å‘åŒ…æ‹¬å‰ç«¯å’Œåç«¯å¼€å‘ã€‚å‰ç«¯ä½¿ç”¨HTMLã€CSSã€JavaScriptã€‚
åç«¯å¯ä»¥ä½¿ç”¨Pythonçš„Flaskå’ŒDjangoæ¡†æ¶ã€‚
RESTful APIæ˜¯ç°ä»£Webåº”ç”¨çš„æ ‡å‡†æ¥å£è®¾è®¡æ–¹å¼ã€‚""",
            "metadata": {"title": "Webå¼€å‘æŠ€æœ¯", "category": "web", "language": "python"}
        },
        {
            "content": """Gitæ˜¯åˆ†å¸ƒå¼ç‰ˆæœ¬æ§åˆ¶ç³»ç»Ÿï¼Œç”¨äºè·Ÿè¸ªä»£ç å˜æ›´ã€‚
å¸¸ç”¨å‘½ä»¤åŒ…æ‹¬git addã€git commitã€git pushã€git pullç­‰ã€‚
GitHubæ˜¯æœ€æµè¡Œçš„ä»£ç æ‰˜ç®¡å¹³å°ï¼Œæ”¯æŒå›¢é˜Ÿåä½œå’Œå¼€æºé¡¹ç›®ã€‚""",
            "metadata": {"title": "Gitç‰ˆæœ¬æ§åˆ¶", "category": "tools", "language": "general"}
        },
        {
            "content": """æ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„å­é›†ï¼Œä½¿ç”¨å¤šå±‚ç¥ç»ç½‘ç»œã€‚
å·ç§¯ç¥ç»ç½‘ç»œ(CNN)ç”¨äºå›¾åƒè¯†åˆ«ï¼Œå¾ªç¯ç¥ç»ç½‘ç»œ(RNN)ç”¨äºåºåˆ—æ•°æ®ã€‚
Transformeræ¨¡å‹revolutionizedè‡ªç„¶è¯­è¨€å¤„ç†é¢†åŸŸã€‚""",
            "metadata": {"title": "æ·±åº¦å­¦ä¹ ", "category": "ai", "language": "python"}
        },
        {
            "content": """Dockeræ˜¯å®¹å™¨åŒ–æŠ€æœ¯ï¼Œå¯ä»¥æ‰“åŒ…åº”ç”¨å’Œä¾èµ–ç¯å¢ƒã€‚
Kubernetesç”¨äºå®¹å™¨ç¼–æ’å’Œç®¡ç†ã€‚
å®¹å™¨æŠ€æœ¯ç®€åŒ–äº†åº”ç”¨éƒ¨ç½²å’Œæ‰©å±•ã€‚""",
            "metadata": {"title": "å®¹å™¨æŠ€æœ¯", "category": "devops", "language": "general"}
        },
        {
            "content": """æ•°æ®åˆ†æä½¿ç”¨ç»Ÿè®¡æ–¹æ³•ä»æ•°æ®ä¸­æå–æ´å¯Ÿã€‚
Pythonçš„pandasåº“æä¾›å¼ºå¤§çš„æ•°æ®å¤„ç†åŠŸèƒ½ã€‚
æ•°æ®å¯è§†åŒ–å·¥å…·åŒ…æ‹¬matplotlibã€seabornç­‰ã€‚""",
            "metadata": {"title": "æ•°æ®åˆ†æ", "category": "data-science", "language": "python"}
        }
    ]
    
    # è·å–æœåŠ¡ (ä½¿ç”¨æœ¬åœ°embeddingæ¨¡å‹)
    embedding_service = get_embedding_service(provider=EmbeddingProvider.LOCAL)
    vector_store = get_vector_store("test_collection")
    
    # æ¸…ç©ºç°æœ‰æ•°æ®
    await vector_store.clear()
    print("âœ“ æ¸…ç©ºç°æœ‰æ•°æ®")
    
    # åˆ›å»ºDocumentå¯¹è±¡
    documents = []
    for i, doc_data in enumerate(test_docs):
        doc = Document(
            content=doc_data["content"],
            metadata=doc_data["metadata"],
            doc_id=f"test_doc_{i}"
        )
        documents.append(doc)
    
    # æ‰¹é‡ç”Ÿæˆembedding
    contents = [doc.content for doc in documents]
    embeddings = await embedding_service.embed_batch(contents)
    
    # æ·»åŠ åˆ°å‘é‡æ•°æ®åº“
    for doc, embedding in zip(documents, embeddings):
        doc.embedding = embedding
    
    doc_ids = await vector_store.add_documents(documents)
    print(f"âœ“ æ·»åŠ  {len(doc_ids)} ä¸ªæµ‹è¯•æ–‡æ¡£")
    
    # éªŒè¯
    stats = await vector_store.get_stats()
    print(f"âœ“ å‘é‡åº“ç»Ÿè®¡: {stats['document_count']} ä¸ªæ–‡æ¡£")
    
    print("\nâœ… æµ‹è¯•ç¯å¢ƒå‡†å¤‡å®Œæˆ")
    return vector_store


async def test_semantic_search():
    """æµ‹è¯•è¯­ä¹‰æœç´¢"""
    print("\n" + "="*60)
    print("æµ‹è¯•1: è¯­ä¹‰æœç´¢ (Semantic Search)")
    print("="*60)
    
    retrieval_service = get_retrieval_service("test_collection")
    
    # æµ‹è¯•ç”¨ä¾‹
    test_queries = [
        "ä»€ä¹ˆæ˜¯Pythonç¼–ç¨‹è¯­è¨€ï¼Ÿ",
        "æœºå™¨å­¦ä¹ çš„å¸¸ç”¨ç®—æ³•æœ‰å“ªäº›ï¼Ÿ",
        "æ•°æ®åº“çš„ç±»å‹"
    ]
    
    for i, query in enumerate(test_queries):
        print(f"\n[æŸ¥è¯¢ {i+1}] {query}")
        
        results = await retrieval_service.retrieve(
            query=query,
            mode=RetrievalMode.SEMANTIC,
            k=3
        )
        
        print(f"âœ“ è¿”å› {len(results)} ä¸ªç»“æœ:")
        for j, result in enumerate(results):
            title = result.document.metadata.get('title', 'Unknown')
            print(f"  {j+1}. {title}")
            print(f"     ç›¸å…³åº¦: {result.score:.3f}")
            print(f"     å†…å®¹: {result.document.content[:60]}...")
    
    print("\nâœ… è¯­ä¹‰æœç´¢æµ‹è¯•é€šè¿‡")


async def test_keyword_search():
    """æµ‹è¯•å…³é”®è¯æœç´¢"""
    print("\n" + "="*60)
    print("æµ‹è¯•2: å…³é”®è¯æœç´¢ (Keyword Search)")
    print("="*60)
    
    retrieval_service = get_retrieval_service("test_collection")
    
    test_queries = [
        "Python TensorFlow",
        "æ•°æ®åº“ SQL NoSQL",
        "Git GitHub"
    ]
    
    for i, query in enumerate(test_queries):
        print(f"\n[æŸ¥è¯¢ {i+1}] {query}")
        
        results = await retrieval_service.retrieve(
            query=query,
            mode=RetrievalMode.KEYWORD,
            k=3
        )
        
        print(f"âœ“ è¿”å› {len(results)} ä¸ªç»“æœ:")
        for j, result in enumerate(results):
            title = result.document.metadata.get('title', 'Unknown')
            matched_kw = result.metadata.get('matched_keywords', [])
            print(f"  {j+1}. {title}")
            print(f"     åˆ†æ•°: {result.score:.3f}")
            print(f"     åŒ¹é…å…³é”®è¯: {', '.join(matched_kw[:5])}")
    
    print("\nâœ… å…³é”®è¯æœç´¢æµ‹è¯•é€šè¿‡")


async def test_hybrid_search():
    """æµ‹è¯•æ··åˆæ£€ç´¢"""
    print("\n" + "="*60)
    print("æµ‹è¯•3: æ··åˆæ£€ç´¢ (Hybrid Search)")
    print("="*60)
    
    retrieval_service = get_retrieval_service("test_collection")
    
    test_queries = [
        "Pythonæœºå™¨å­¦ä¹ æ¡†æ¶",
        "å®¹å™¨åŒ–éƒ¨ç½²æŠ€æœ¯",
        "æ•°æ®åˆ†æå¯è§†åŒ–"
    ]
    
    for i, query in enumerate(test_queries):
        print(f"\n[æŸ¥è¯¢ {i+1}] {query}")
        
        # å¯¹æ¯”ä¸‰ç§æ¨¡å¼
        modes = [
            (RetrievalMode.SEMANTIC, "è¯­ä¹‰"),
            (RetrievalMode.KEYWORD, "å…³é”®è¯"),
            (RetrievalMode.HYBRID, "æ··åˆ")
        ]
        
        for mode, mode_name in modes:
            results = await retrieval_service.retrieve(
                query=query,
                mode=mode,
                k=2
            )
            
            print(f"\n  [{mode_name}æ¨¡å¼]")
            for j, result in enumerate(results):
                title = result.document.metadata.get('title', 'Unknown')
                print(f"    {j+1}. {title} (åˆ†æ•°: {result.score:.3f})")
    
    print("\nâœ… æ··åˆæ£€ç´¢æµ‹è¯•é€šè¿‡")


async def test_rerank():
    """æµ‹è¯•é‡æ’åº"""
    print("\n" + "="*60)
    print("æµ‹è¯•4: é‡æ’åº (Rerank)")
    print("="*60)
    
    retrieval_service = get_retrieval_service("test_collection", enable_rerank=True)
    
    query = "Pythonæ•°æ®å¤„ç†å’Œåˆ†æ"
    
    print(f"\n[æŸ¥è¯¢] {query}")
    
    # å¯¹æ¯”é‡æ’åºå‰å
    print("\n[é‡æ’åºå‰ - çº¯è¯­ä¹‰æœç´¢]")
    results_before = await retrieval_service.retrieve(
        query=query,
        mode=RetrievalMode.SEMANTIC,
        k=5
    )
    
    for i, result in enumerate(results_before):
        title = result.document.metadata.get('title', 'Unknown')
        print(f"  {i+1}. {title} (åˆ†æ•°: {result.score:.3f})")
    
    print("\n[é‡æ’åºå]")
    results_after = await retrieval_service.retrieve(
        query=query,
        mode=RetrievalMode.RERANK,
        k=5
    )
    
    for i, result in enumerate(results_after):
        title = result.document.metadata.get('title', 'Unknown')
        rerank_score = result.metadata.get('rerank_score', 0)
        print(f"  {i+1}. {title}")
        print(f"      é‡æ’åºåˆ†æ•°: {rerank_score:.3f}")
    
    print("\nâœ… é‡æ’åºæµ‹è¯•é€šè¿‡")


async def test_metadata_filtering():
    """æµ‹è¯•å…ƒæ•°æ®è¿‡æ»¤"""
    print("\n" + "="*60)
    print("æµ‹è¯•5: å…ƒæ•°æ®è¿‡æ»¤")
    print("="*60)
    
    retrieval_service = get_retrieval_service("test_collection")
    
    query = "æŠ€æœ¯ä»‹ç»"
    
    # æµ‹è¯•ä¸åŒçš„è¿‡æ»¤æ¡ä»¶
    filters = [
        ({"category": "ai"}, "AIåˆ†ç±»"),
        ({"language": "python"}, "Pythonç›¸å…³"),
        ({"category": "database"}, "æ•°æ®åº“åˆ†ç±»")
    ]
    
    for filter_dict, description in filters:
        print(f"\n[è¿‡æ»¤æ¡ä»¶: {description}]")
        
        results = await retrieval_service.retrieve(
            query=query,
            mode=RetrievalMode.SEMANTIC,
            k=5,
            filter_metadata=filter_dict
        )
        
        print(f"âœ“ è¿”å› {len(results)} ä¸ªç»“æœ:")
        for i, result in enumerate(results):
            title = result.document.metadata.get('title', 'Unknown')
            category = result.document.metadata.get('category', 'Unknown')
            print(f"  {i+1}. {title} (åˆ†ç±»: {category})")
    
    print("\nâœ… å…ƒæ•°æ®è¿‡æ»¤æµ‹è¯•é€šè¿‡")


async def test_context_generation():
    """æµ‹è¯•ä¸Šä¸‹æ–‡ç”Ÿæˆï¼ˆç”¨äºAgenté›†æˆï¼‰"""
    print("\n" + "="*60)
    print("æµ‹è¯•6: ä¸Šä¸‹æ–‡ç”Ÿæˆ (Agenté›†æˆ)")
    print("="*60)
    
    retrieval_service = get_retrieval_service("test_collection")
    
    query = "å¦‚ä½•ä½¿ç”¨Pythonè¿›è¡Œæœºå™¨å­¦ä¹ ï¼Ÿ"
    
    print(f"\n[æŸ¥è¯¢] {query}")
    
    # æ£€ç´¢å¹¶ç”Ÿæˆä¸Šä¸‹æ–‡
    results, context = await retrieval_service.retrieve_with_context(
        query=query,
        mode=RetrievalMode.HYBRID,
        k=3,
        max_context_length=500
    )
    
    print(f"\nâœ“ æ£€ç´¢åˆ° {len(results)} ä¸ªç›¸å…³æ–‡æ¡£")
    print(f"âœ“ ç”Ÿæˆä¸Šä¸‹æ–‡é•¿åº¦: {len(context)} å­—ç¬¦")
    
    print("\nç”Ÿæˆçš„ä¸Šä¸‹æ–‡:")
    print("-" * 60)
    print(context)
    print("-" * 60)
    
    # éªŒè¯ä¸Šä¸‹æ–‡æ ¼å¼
    assert "### æ¥æº" in context, "ä¸Šä¸‹æ–‡åº”åŒ…å«æ¥æºæ ‡è®°"
    assert "ç›¸å…³åº¦:" in context, "ä¸Šä¸‹æ–‡åº”åŒ…å«ç›¸å…³åº¦ä¿¡æ¯"
    
    print("\nâœ… ä¸Šä¸‹æ–‡ç”Ÿæˆæµ‹è¯•é€šè¿‡")


async def test_performance():
    """æµ‹è¯•æ£€ç´¢æ€§èƒ½"""
    print("\n" + "="*60)
    print("æµ‹è¯•7: æ€§èƒ½æµ‹è¯•")
    print("="*60)
    
    retrieval_service = get_retrieval_service("test_collection")
    
    import time
    
    queries = [
        "Pythonç¼–ç¨‹",
        "æœºå™¨å­¦ä¹ ç®—æ³•",
        "æ•°æ®åº“æŠ€æœ¯",
        "Webå¼€å‘",
        "ç‰ˆæœ¬æ§åˆ¶"
    ]
    
    print("\næµ‹è¯•ä¸åŒæ£€ç´¢æ¨¡å¼çš„æ€§èƒ½:")
    
    modes = [
        (RetrievalMode.SEMANTIC, "è¯­ä¹‰æœç´¢"),
        (RetrievalMode.KEYWORD, "å…³é”®è¯æœç´¢"),
        (RetrievalMode.HYBRID, "æ··åˆæ£€ç´¢"),
        (RetrievalMode.RERANK, "é‡æ’åº")
    ]
    
    for mode, mode_name in modes:
        start_time = time.time()
        
        for query in queries:
            await retrieval_service.retrieve(query, mode=mode, k=5)
        
        elapsed = time.time() - start_time
        avg_time = elapsed / len(queries) * 1000  # ms
        
        print(f"\n  [{mode_name}]")
        print(f"    æ€»æ—¶é—´: {elapsed:.2f}s")
        print(f"    å¹³å‡æ—¶é—´: {avg_time:.1f}ms/æŸ¥è¯¢")
        
        # æ€§èƒ½æ–­è¨€
        assert avg_time < 1000, f"{mode_name}å¹³å‡å“åº”æ—¶é—´åº”å°äº1ç§’"
    
    print("\nâœ… æ€§èƒ½æµ‹è¯•é€šè¿‡")


async def test_integration():
    """é›†æˆæµ‹è¯•ï¼šå®Œæ•´æ£€ç´¢æµç¨‹"""
    print("\n" + "="*60)
    print("æµ‹è¯•8: é›†æˆæµ‹è¯• - å®Œæ•´æ£€ç´¢æµç¨‹")
    print("="*60)
    
    print("\n[æ­¥éª¤1] åˆå§‹åŒ–æ£€ç´¢æœåŠ¡")
    retrieval_service = get_retrieval_service("test_collection")
    stats = retrieval_service.get_stats()
    print(f"âœ“ æœåŠ¡åˆå§‹åŒ–å®Œæˆ")
    print(f"  é›†åˆåç§°: {stats['collection_name']}")
    print(f"  é»˜è®¤è¿”å›æ•°: {stats['default_k']}")
    print(f"  æ–‡æ¡£æ€»æ•°: {stats['vector_store_stats']['document_count']}")
    
    print("\n[æ­¥éª¤2] æ‰§è¡Œæ··åˆæ£€ç´¢")
    query = "Pythonåœ¨äººå·¥æ™ºèƒ½é¢†åŸŸçš„åº”ç”¨"
    results = await retrieval_service.retrieve(
        query=query,
        mode=RetrievalMode.HYBRID,
        k=3,
        score_threshold=0.1
    )
    print(f"âœ“ æ£€ç´¢å®Œæˆ: {len(results)} ä¸ªç»“æœ")
    
    print("\n[æ­¥éª¤3] éªŒè¯ç»“æœè´¨é‡")
    for i, result in enumerate(results):
        # éªŒè¯å¿…éœ€å­—æ®µ
        assert result.document is not None, "æ–‡æ¡£ä¸èƒ½ä¸ºç©º"
        assert result.score >= 0.0, "åˆ†æ•°åº”ä¸ºéè´Ÿæ•°"
        assert result.rank == i + 1, f"æ’ååº”ä¸º {i+1}"
        assert result.retrieval_mode == RetrievalMode.HYBRID, "æ£€ç´¢æ¨¡å¼åº”ä¸ºHYBRID"
        
        print(f"  âœ“ ç»“æœ {i+1} éªŒè¯é€šè¿‡")
    
    print("\n[æ­¥éª¤4] ç”ŸæˆAgentä¸Šä¸‹æ–‡")
    results, context = await retrieval_service.retrieve_with_context(
        query=query,
        mode=RetrievalMode.HYBRID,
        k=2,
        max_context_length=300
    )
    
    assert len(context) <= 350, "ä¸Šä¸‹æ–‡é•¿åº¦åº”åœ¨é™åˆ¶èŒƒå›´å†…"
    assert len(context) > 0, "ä¸Šä¸‹æ–‡ä¸åº”ä¸ºç©º"
    print(f"âœ“ ä¸Šä¸‹æ–‡ç”ŸæˆæˆåŠŸ ({len(context)} å­—ç¬¦)")
    
    print("\nâœ… é›†æˆæµ‹è¯•é€šè¿‡")


async def cleanup():
    """æ¸…ç†æµ‹è¯•æ•°æ®"""
    print("\n" + "="*60)
    print("æ¸…ç†æµ‹è¯•æ•°æ®")
    print("="*60)
    
    vector_store = get_vector_store("test_collection")
    await vector_store.clear()
    print("âœ“ æµ‹è¯•æ•°æ®å·²æ¸…ç†")


async def main():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("\n" + "="*60)
    print("RAGç³»ç»Ÿ Day 4-5 æµ‹è¯•å¥—ä»¶")
    print("æµ‹è¯•èŒƒå›´: æ£€ç´¢æœåŠ¡ (è¯­ä¹‰/å…³é”®è¯/æ··åˆ/é‡æ’åº)")
    print("="*60)
    
    try:
        # å‡†å¤‡æµ‹è¯•ç¯å¢ƒ
        await test_setup()
        
        # è¿è¡Œæ‰€æœ‰æµ‹è¯•
        await test_semantic_search()
        await test_keyword_search()
        await test_hybrid_search()
        await test_rerank()
        await test_metadata_filtering()
        await test_context_generation()
        await test_performance()
        await test_integration()
        
        # æ¸…ç†
        await cleanup()
        
        print("\n" + "="*60)
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡!")
        print("="*60)
        print("\nâœ… Day 4-5 äº¤ä»˜ç‰©éªŒè¯å®Œæˆ:")
        print("  1. è¯­ä¹‰æœç´¢ (Semantic Search) âœ“")
        print("  2. å…³é”®è¯æœç´¢ (Keyword Search) âœ“")
        print("  3. æ··åˆæ£€ç´¢ (Hybrid Search - RRF) âœ“")
        print("  4. é‡æ’åº (Rerank) âœ“")
        print("  5. å…ƒæ•°æ®è¿‡æ»¤ âœ“")
        print("  6. ä¸Šä¸‹æ–‡ç”Ÿæˆ (Agenté›†æˆ) âœ“")
        print("  7. æ€§èƒ½éªŒè¯ (<1s/æŸ¥è¯¢) âœ“")
        print("  8. é›†æˆæµ‹è¯• âœ“")
        
        return 0
        
    except AssertionError as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        return 1
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return 1


if __name__ == "__main__":
    exit(asyncio.run(main()))
