#!/usr/bin/env python3
"""
æµ‹è¯•Promptç³»ç»Ÿ
éªŒè¯å„ä¸ªAgentçš„Promptç”Ÿæˆæ•ˆæœ
"""
import asyncio
from app.core.prompt_service import prompt_service, get_agent_prompt, get_agent_messages
from app.core.cot_prompts import CoTPattern
from app.core.llm_factory import get_provider
from app.core.llm_config import LLMProviderType
from app.core.llm_provider import ChatRequest, Message


async def test_basic_prompts():
    """æµ‹è¯•åŸºç¡€Promptç”Ÿæˆ"""
    print("=" * 60)
    print("æµ‹è¯•1: åŸºç¡€Promptç”Ÿæˆ")
    print("=" * 60)
    
    agents = ["Coordinator", "ScheduleAgent", "TaskAgent", "CodeAgent"]
    
    for agent_name in agents:
        prompt = get_agent_prompt(
            agent_name,
            "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•è¾“å…¥"
        )
        print(f"\n### {agent_name} Prompt (å‰200å­—ç¬¦):")
        print(prompt[:200] + "...")
        print()


async def test_few_shot_prompts():
    """æµ‹è¯•Few-shot Prompt"""
    print("=" * 60)
    print("æµ‹è¯•2: Few-shot Promptç”Ÿæˆ")
    print("=" * 60)
    
    prompt = get_agent_prompt(
        "ScheduleAgent",
        "ä¸‹å‘¨ä¸‰ä¸‹åˆ2ç‚¹å’Œæå››å¼€ä¼šè®¨è®ºæ–°äº§å“",
        use_few_shot=True,
        num_examples=2
    )
    
    print("\n### ScheduleAgent Few-shot Prompt (å‰400å­—ç¬¦):")
    print(prompt[:400] + "...")
    print()


async def test_cot_prompts():
    """æµ‹è¯•Chain-of-Thought Prompt"""
    print("=" * 60)
    print("æµ‹è¯•3: Chain-of-Thought Promptç”Ÿæˆ")
    print("=" * 60)
    
    prompt = get_agent_prompt(
        "CalculationAgent",
        "ä¸€ä¸ªå•†å“åŸä»·200å…ƒï¼Œå…ˆæ‰“8æŠ˜ï¼Œå†æ»¡300å‡50ï¼Œä¹°2ä»¶æœ€ç»ˆå¤šå°‘é’±ï¼Ÿ",
        use_cot=True,
        cot_pattern=CoTPattern.STEP_BY_STEP
    )
    
    print("\n### CalculationAgent CoT Prompt (å‰500å­—ç¬¦):")
    print(prompt[:500] + "...")
    print()


async def test_combined_prompts():
    """æµ‹è¯•ç»„åˆPromptï¼ˆFew-shot + CoTï¼‰"""
    print("=" * 60)
    print("æµ‹è¯•4: ç»„åˆPrompt (Few-shot + CoT)")
    print("=" * 60)
    
    prompt = get_agent_prompt(
        "CodeAgent",
        "ç”¨Pythonå®ç°äºŒåˆ†æŸ¥æ‰¾ç®—æ³•",
        use_few_shot=True,
        use_cot=True,
        cot_pattern=CoTPattern.STEP_BY_STEP,
        constraints=[
            "ä»£ç éœ€è¦æœ‰è¯¦ç»†æ³¨é‡Š",
            "åŒ…å«æµ‹è¯•ç”¨ä¾‹",
            "æ—¶é—´å¤æ‚åº¦O(log n)"
        ],
        output_format="```python\nä»£ç \n```\n\nè§£é‡Š: ..."
    )
    
    print("\n### CodeAgent ç»„åˆPrompt (å‰600å­—ç¬¦):")
    print(prompt[:600] + "...")
    print()


async def test_messages_format():
    """æµ‹è¯•æ¶ˆæ¯æ ¼å¼ï¼ˆChat APIï¼‰"""
    print("=" * 60)
    print("æµ‹è¯•5: æ¶ˆæ¯æ ¼å¼ç”Ÿæˆ")
    print("=" * 60)
    
    messages = get_agent_messages(
        "TaskAgent",
        "å¸®æˆ‘è§„åˆ’ä¸€ä¸‹æœ¬å‘¨çš„å­¦ä¹ ä»»åŠ¡",
        use_few_shot=True,
        num_examples=1
    )
    
    print(f"\n### TaskAgent æ¶ˆæ¯åˆ—è¡¨ ({len(messages)}æ¡æ¶ˆæ¯):")
    for i, msg in enumerate(messages, 1):
        print(f"\næ¶ˆæ¯ {i} ({msg['role']}):")
        content = msg['content']
        if len(content) > 200:
            print(content[:200] + "...")
        else:
            print(content)
    print()


async def test_real_llm_call():
    """æµ‹è¯•çœŸå®LLMè°ƒç”¨"""
    print("=" * 60)
    print("æµ‹è¯•6: çœŸå®LLMè°ƒç”¨æµ‹è¯•")
    print("=" * 60)
    
    try:
        # è·å–Provider
        provider = get_provider(LLMProviderType.OPENAI)
        
        # ç”ŸæˆPrompt
        messages = get_agent_messages(
            "InfoRetrievalAgent",
            "ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿè¯·ç”¨ä¸€å¥è¯è§£é‡Š",
            use_few_shot=False,
            constraints=["å›ç­”è¦ç®€æ´", "ä¸è¶…è¿‡50å­—"]
        )
        
        # è½¬æ¢ä¸ºChatRequestæ ¼å¼
        request_messages = [
            Message(role=msg['role'], content=msg['content'])
            for msg in messages
        ]
        
        request = ChatRequest(
            messages=request_messages,
            temperature=0.7,
            max_tokens=100
        )
        
        print("\n### å‘é€è¯·æ±‚åˆ°LLM...")
        response = await provider.chat(request)
        
        print(f"\nâœ… LLMå“åº”:")
        print(response.content)
        print(f"\nğŸ“Š Tokenä½¿ç”¨: {response.usage}")
        
    except Exception as e:
        print(f"\nâŒ LLMè°ƒç”¨å¤±è´¥: {str(e)}")
        print("æç¤º: è¯·ç¡®ä¿é…ç½®äº†æœ‰æ•ˆçš„APIå¯†é’¥")


async def test_prompt_statistics():
    """æµ‹è¯•Promptç»Ÿè®¡ä¿¡æ¯"""
    print("\n" + "=" * 60)
    print("Promptç³»ç»Ÿç»Ÿè®¡")
    print("=" * 60)
    
    templates = prompt_service.library.list_templates()
    print(f"\nâœ… å·²æ³¨å†Œçš„Promptæ¨¡æ¿: {len(templates)}ä¸ª")
    print("\næ¨¡æ¿åˆ—è¡¨:")
    for i, name in enumerate(templates, 1):
        template = prompt_service.library.get(name)
        print(f"  {i}. {name} (v{template.version})")
    
    print(f"\nâœ… æ”¯æŒçš„CoTæ¨¡å¼: {len(CoTPattern.__members__)}ç§")
    print("CoTæ¨¡å¼åˆ—è¡¨:")
    for i, pattern in enumerate(CoTPattern, 1):
        print(f"  {i}. {pattern.value}")
    
    print("\n" + "=" * 60)


async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("\nğŸš€ å¼€å§‹æµ‹è¯•Promptç³»ç»Ÿ...\n")
    
    # è¿è¡Œæ‰€æœ‰æµ‹è¯•
    await test_basic_prompts()
    await test_few_shot_prompts()
    await test_cot_prompts()
    await test_combined_prompts()
    await test_messages_format()
    await test_real_llm_call()
    await test_prompt_statistics()
    
    print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•å®Œæˆï¼")
    print("\nğŸ’¡ Promptç³»ç»Ÿç‰¹æ€§:")
    print("  âœ… 21ä¸ªAgentä¸“ä¸šPrompt")
    print("  âœ… Few-shotç¤ºä¾‹æ”¯æŒ")
    print("  âœ… 5ç§Chain-of-Thoughtæ¨¡å¼")
    print("  âœ… çµæ´»çš„Promptç»„è£…")
    print("  âœ… Chat APIæ ¼å¼æ”¯æŒ")
    print()


if __name__ == "__main__":
    asyncio.run(main())
